
\documentclass{scrartcl}
%\documentclass[a5paper]{article}

%\usepackage[solutionfiles]{optional}
\usepackage[nosolutionfiles]{optional}
\opt{nosolutionfiles}{\usepackage[nosolutionfiles]{answers}}
\opt{solutionfiles}{\usepackage{answers}}

\usepackage{preamble}

% handle indentation below figure captions
\setcapwidth[c]{.8\textwidth}
\setcapwidth{0.95\textwidth}
%\setcapindent{0pt}
%\addtokomafont{caption}{\centering}

%\usepackage[top=5mm, left=5mm, right=5mm, bottom=2cm]{geometry}

\newenvironment{pyconcodeblock}%
 {\VerbatimEnvironment
  \begin{VerbatimOut}{temp.py}}%
 {\end{VerbatimOut}%
  \pyconc{exec(compile(open('temp.py', 'rb').read(), 'temp.py', 'exec'))}%
  \inputpygments{python}{temp.py}}





\title{Queueing simulations}
\author{N.D. Van Foreest}
\begin{document}
\maketitle

\Opensolutionfile{hint}
\Opensolutionfile{ans}

document in de levelcrossing illustration directory. Kijk even goed wat ik eigenlijk allemaal al heb.

\section{Introduction}
Typically a queueing system is subject to rules about when to allow jobs to enter the system or to adapt the service capacity. Such a decision rule is typically called a \emph{policy}.  The theoretical analysis of the efficacy of policies is often very hard, while with simulation it is doable.  In this document we present a number of cases to see how simulation can be used to analyze and improve queueing systems. Each case is organized like this.


\begin{enumerate}
\item First hour
  \begin{enumerate}
\item Case description
\item Modeling of the queueing system, the policy structure and the relevant KPIs (key performance indicators, such as cost, or utilization of the server, and so on) to evaluate the effect policy
\item Implementation of the model in python. 
  \end{enumerate}
\item Second hour
  \begin{enumerate}
  \item Download, from nestor, the code written by the authors
  \item Simulate a number of scenarios
  \item Adapt the code to analyze some further policies/scenarios.
  \end{enumerate}
\end{enumerate}


We expect you to work in a groups of 2 to 3 students and bring a laptop with an \emph{installed and working} python environment, such as anaconda.  There are also python environments available on the web, but that is typically a bit less practical than running the code on your own machine. 


Our code is not the most efficient, or fast. Rather, we focus on clarity of code so that the underlying reasoning is as clear as possible. Once our ideas and code are correct, we can start optimizing, if this is necessary. 

\section{Exponential distribution}

The aim of this tutorial is to show, empirically, a fascination fact: even for very small populations in which individuals decide independently to visit a server (a shop, a hospital, etc),  the  exponential distribution is a good model for the interarrival times as seen by the server.  We will develop a simulation to motivate this `fact of nature'.  One important step in this process is to compute the emperical distribution. As this is much more interesting (and challenging) than you might think\footnote{If you search the web, you will see that computing the emperical density function is even more challenging.}, we start with this. Once we can compute emperical distribution functions, we are in good shape to set up the rest of the simulation. 

\subsection{Emperical distributions}
\label{sec:emper-distr}

Before designing an algorithm, it is best to start with a simple numerical example and try to formalize the steps we take in the process.

\begin{exercise}
  Suppose you are given the following numbers: \pyb{a = [3.2, 4, 4, 1.3, 8.5, 9]}, what steps  do you take to  turn this into the empirical distribution function, which is defined as
  \begin{equation}
    \label{eq:1}
    F(x) = \frac{\# \{i : a_i \leq x\}}{n}, 
  \end{equation}
  with $n$ is the length of $a$?

Can you turn it into an algorithm? (Just attempt to design an algorithm. Even if you don't succeed, trying is important.)

  \begin{solution}
We put the algorithm in a function so that we can use it later.
    \begin{pyblock}
def cdf(a):
    a = sorted(a)
    m, M = int(min(a)), int(max(a))+1
    # Since we know that a is sorted, this would be better, but less clear perhaps: 
    # m, M = int(a[0]), int(a[-1])+1 

    F = dict() # store the function i \to F[i]
    F[m-1]=0  # since F[x] = 0 for all x < m
    i = 0
    for x in range(m, M):
        F[x] = F[x-1]
        while i< len(a) and a[i] <= x:
            F[x] += 1
            i += 1

    # normalize
    for x in F.keys(): 
        F[x] /= len(a)

    return F
    \end{pyblock}

If we run this
\begin{pyblock}
F = cdf(a)
print(F)
\end{pyblock}
we get
\printpythontex
  \end{solution}
\end{exercise}

\begin{exercise}
  The algorithm provided in the previous exercise is simple, but not completely correct. What is wrong?
  \begin{solution}
    We have to guess the support of $F$ (the set of points where $F$ makes the jumps) upfront, and we concentrated the support on the integers. However $F$ makes jumps at floats, for instance  at $3.2$. 
  \end{solution}
\end{exercise}

Suppose we would consider the sorted version of $a$, which we also call $a$, i.e., \pyb{a = sorted(a)}. Observe that the function $i\to a_i$ is the inverse of $F$, except for normalization.

\begin{exercise}
  Plot the function $i\to a_i$ by hand, and check that this is indeed the inverse of $F$ (except for the normalization).

  \begin{solution}
    In the answer we let the computer do all the work.  Note that \pyv{matplotlib} is a library of functions to provide plotting functionality.

\begin{pyblock}
import matplotlib
matplotlib.use('pdf') 
import matplotlib.pyplot as plt

I = range(0, len(a))
plt.plot(I, sorted(a))
plt.savefig("dummy_plot_1.pdf")
plt.cla() # clear the figure so that we can overwrite it later.
\end{pyblock}

\begin{center}
\includegraphics[scale=0.5]{dummy_plot_1.pdf}
\end{center}

  \end{solution}
\end{exercise}

\begin{exercise}
  Find now a way to invert $i\to a_i$, normalize, and make a new plot. 
  \begin{solution}
Here is one way. Note that we already imported matplotlib, so we don't have to that again.
\begin{pyblock}
def cdf(a):  
    y = range(1, len(a)+1)
    y = [yy/len(a) for yy in y] # normalize
    x = sorted(a)
    return x, y

x, y = cdf(a)

plt.plot(x, y)
plt.savefig("dummy_plot_2.pdf")
plt.cla() # clear the figure so that we can overwrite it later.
\end{pyblock}
Why do we start $y$ with 1?


\begin{center}
\includegraphics[scale=0.5]{dummy_plot_2.pdf}
\end{center}
  \end{solution}
\end{exercise}


The result is still not entirely OK, as the graph of the distribution does not make jumps, which it should.  The rest of this section is about how to repair this and a faster way to compute the cdf. You can skip this if you are not interested. 



\begin{exercise}
See how to repair for the jumps with the  drawstyle in the plot function of matplotlib.
  \begin{solution}
With the drawstyle option: 
\begin{pyblock}
plt.plot(x, y,  drawstyle = 'steps-pre')
plt.savefig("dummy_plot_drawstyle.pdf")
plt.cla() # clear the figure so that we can overwrite it later.
\end{pyblock}


\begin{center}
\includegraphics[scale=0.5]{dummy_plot_drawstyle.pdf}
\end{center}

But now we have  vertical lines. To remove those, we can use hlines.

\begin{pyblock}
y = range(0, len(a)+1)
y = [yy/len(a) for yy in y] # normalize
a = sorted(a)
left = [0] + a
right = a + [10]

plt.hlines(y, left, right)
plt.savefig("dummy_plot_lines.pdf")
plt.cla() # clear the figure so that we can overwrite it later.
\end{pyblock}

\begin{center}
\includegraphics[scale=0.5]{dummy_plot_lines.pdf}
\end{center}

There  we are!.
  \end{solution}
\end{exercise}

\begin{exercise}
Finally, can you use the exceedingly useful \pyv{numpy} library which provides an enormous amount of functions to handle large (multi-dimensional) arrays with numbers. 
In particular,  you might want to check the documentation of the following numpy functions. 
\begin{enumerate}
\item \pyv{numpy.unique}
\item \pyv{numpy.sort}
\item \pyv{numpy.cumsum}
\item \pyv{numpy.sum}
\end{enumerate}
\begin{solution}
Here it is.
\begin{pyblock}
# we first need to fix some initial settings.
import numpy as np

def cdf(X):
    # remove multiple occurences of the same value
    unique, count = np.unique(np.sort(X), return_counts=True)
    x = unique
    y = count.cumsum()/count.sum()
    return x, y

x, y = cdf(a)
\end{pyblock}

\end{solution}
\end{exercise}

\subsection{Simulations}
\label{sec:simulations}



The aim this tutorial is to build Figures 1.1, 1.2., and 1.3 of the queueing book.  (Read the description that underlies these figures.) Actually, we will not focus on  density functions here, but on the distributions.  

\begin{exercise}
  Make a plan of the steps you have to carry out to make Figure 1.1. In the next set of exercises we'll carry out these steps. So please do not read on before having thought about this problem. 
  \begin{hint}
Spend 5 minutes to think about how to approach the problem and how to chop it up into simple steps. Then organize the steps into a logical sequence. Don't worry at first about how to convert your ideas into computer code.   Coding is a separate activity. 
  \end{hint}
  \begin{solution}
    \begin{enumerate}
    \item Generate  uniform distributed random variables for one customer corresponding to interarrival times.
    \item Plot the interarrival times
    \item Compute (emperical) distribtuion function of the random interarrival times.
    \item Plot the (emperical) distribtuion function
    \item Generate  uniform distributed random variables for multiple customers, e.g., 3. 
    \item Compute the arrival times for each customer.
    \item Merge  the arrival times for all customers. This is the arrival process as seen by the shop.
    \item Compute the interarrival times as seen by the shop
    \item Plot these interarrival times.
    \item Compare to the exponential density with a suitable arrival rate $\lambda$. 
    \end{enumerate}
  \end{solution}
\end{exercise}


\begin{exercise}
  Generate 3 random numbers uniformly distributed on $[4,6]$. 

  Read the documentation, on the web, of:
  \begin{enumerate}
  \item  \pyv{scipy.stats.uniform}.  Check in particular the \pyv{rvs()} function. 
  \end{enumerate}

\pyv{scipy} contains numerical recipes, such as solvers for optimization software, solvers for differential equations. \pyv{scipy.stats} contains many probability distributions and numerical methods to operate on these functions. 
\begin{solution}
Copy this code and run it.
\begin{pyverbatim}
# we first need to fix some initial settings.
import numpy as np
import scipy
import matplotlib
matplotlib.use('pdf') 
import matplotlib.pyplot as plt
from scipy.stats import uniform

np.set_printoptions(precision=3) # this is to print not too many digits to the screen

# fix the seed
scipy.random.seed(3) 

# parameters
L = 3  # number of interarrival times

G = uniform(loc=4, scale=2) 
a = G.rvs(L)
print(a)
\end{pyverbatim}
  
\end{solution}

\end{exercise}


\begin{exercise}
Generate $L=300$ random numbers $\sim U[4,6]$ and plot these. Save the figure to a pdf file. You should interpret these random numbers as interarrival times of one customer at a shop (in hours say.)

See
\begin{enumerate}
\item  \pyv{matplotlib.pyplot.plot}
\item \pyv{matplotlib.pyplot.savefig}.
\end{enumerate}
\begin{solution}
Add this code to the other code and run it.
\begin{pyverbatim}
N = 1 # number of customers
L = 300
a = G.rvs(L)

plt.plot(a, label="a")
plt.title("N = {}, L = {}".format(N, L))
plt.legend()
plt.savefig("dummy_plot.pdf")
plt.cla() # clear the figure so that we can overwrite it later.
\end{pyverbatim}
I use the same name for the pdf file, so to prevent having to delete 10 figures or so. If you don't like this, just provide another name. 
\end{solution}
\end{exercise}

\begin{exercise}
Compute  the emperical distribution function of these interarrival times, and plot it.

See:
\begin{enumerate}
\item Look up the definition of the empirical distribution in the queueing book,
\item \pyv{numpy.unique}
\item \pyv{numpy.sort}
\item \pyv{numpy.cumsum}
\item \pyv{numpy.sum}
\end{enumerate}
\begin{solution}
Add this to the other code and run it.
\begin{pyverbatim}
def cdf(X):
    # remove multiple occurences of the same value
    unique, count = np.unique(np.sort(X), return_counts=True)
    x = unique
    y = count.cumsum()/count.sum()
    return x, y

x, y = cdf(a)
plt.plot(x,y,  label="d")
plt.legend()
plt.savefig("dummy_plot.pdf")
plt.cla() # clear the figure
\end{pyverbatim}
\end{solution}
\end{exercise}

\begin{exercise}
We like to compare the emperical distribution to the theoretical distribution of the interarrival times, which is uniform for this case. We can use the Kolmogorov-Smirnov statistic for this comparion. 

See:
\begin{enumerate}
\item Kolmogorov-Smirnov (wikipedia)
\\item \pyv{numpy.max}
\\item \pyv{numpy.abs}
\\item \pyv{scipy.stats.uniform}, the \pyv{cdf} function.
\end{enumerate}

\begin{solution}
Add this to the other code and run it.
\begin{pyverbatim}
def KS(X, F):
    # Compute the Kolmogorov-Smirnov statistic where
    # X are the data points
    # F is the theoretical distribution
    support, y = cdf(X)
    y_theo = np.array([F.cdf(x) for x in support])
    return np.max(np.abs(y-y_theo))

print(KS(a, G))    
\end{pyverbatim}
\end{solution}
\end{exercise}

\begin{exercise}
  Now compute the KS statistics with an exponential distribution with a suitable mean. (What is this suitable mean?).

See:
\begin{enumerate}
\item  \pyv{scipy.stats.expon}
\end{enumerate}


\begin{solution}
Add this to the other code and run it. Since the mean interarrival time is $5$, take $\lambda = 1/5$.

\begin{pyverbatim}
from scipy.stats import expon

labda = 1./5 # lambda is a function in python
E = expon(scale=1/labda) 
print(E.mean()) # to check that we chose the right scale
print(KS(a, E))    
\end{pyverbatim}
\end{solution}
\end{exercise}

\begin{exercise}
  Finally, plot the emperical distribution and the exponential distribution in one graph.
\begin{solution}
Add this to the other code and run it. 
\begin{pyverbatim}
x, y = cdf(a)
plt.plot(x, y,  label="empirical")
plt.plot(x, E.cdf(x),  label="exp")
plt.legend()
plt.savefig("dummy_plot.pdf")
plt.cla() # clear the figure
\end{pyverbatim}
\end{solution}
\end{exercise}

The analysis for one customer is now finished. Lets extend to 3 customers. 

\begin{exercise}
Generate random interarrival times for 3 customers. Then turn this into arrival times for each customer. The shop sees the combined arrival process, so you need to find a way to merge the arrival times of the customers into one arrival process as observed by the shop. Finally, we need to convert this into interrival times to get a distribution of the interarrival times at the shop. 

See:
\begin{enumerate}
\item \pyv{numpy.cumsum}, in particular read about the meaning of axis.
\item \pyv{numpy.flatten}
\item \pyv{numpy.diff}
\end{enumerate}


\begin{solution}
Add this to the other code and run it. 
\begin{pyverbatim}
def superposition(a):
    A = np.cumsum(a, axis=1)
    A = np.sort(A.flatten())
    return np.diff(A)

N, L = 3, 100
a = superposition(G.rvs((N, L)))

E = expon(scale=1./(N*labda)) # the arrival rate of N customers is N times as large
print(E.mean())

x, y = cdf(a)
plt.title("N = {}, L = {}".format(N, L))
plt.plot(x, y,  label="empirical")
plt.plot(x, E.cdf(x),  label="exp")
plt.legend()
plt.savefig("dummy_plot.pdf")
plt.cla() # clear the figure
\end{pyverbatim}

\end{solution}
\end{exercise}

Lets see what happens for $N=10$ customers.

\begin{exercise}
  Compare  the emperical distribution of the interarrival times generated by  $N=10$ customers to the exponential distribution (compute the appropriate arrival rate). Make a plot. 
\begin{solution}
Add this to the other code and run it. 
\begin{pyverbatim}
N, L = 10, 10
a = superposition(G.rvs((N, L)))

E = expon(scale=1/(N*labda))

x, y = cdf(a)
plt.title("N = {}, L = {}".format(N, L))
plt.plot(x, y,  label="empirical")
plt.plot(x, E.cdf(x),  label="exp")
plt.legend()
plt.savefig("dummy_plot.pdf")
plt.cla() # clear the figure
\end{pyverbatim}

\end{solution}
\end{exercise}



\begin{exercise}
  Do the same for $N=10$ customers with normally distributed interarrival times with $\mu=5$, and $\sigma =1$.

See:
\begin{enumerate}
\item \pyv{scipy.stats.norm}
\end{enumerate}

\begin{solution}
Add this to the other code and run it. 
\begin{pyverbatim}
from scipy.stats import norm

N, L = 10, 10
a = superposition(norm(loc=5, scale=1).rvs((N, L)))

plt.title("N = {}, L = {}".format(N, L))
plt.plot(x, y,  label="empirical")
plt.plot(x, E.cdf(x),  label="exp")
plt.legend()
plt.savefig("dummy_plot.pdf")
plt.cla() # clear the figure
\end{pyverbatim}

\end{solution}
\end{exercise}


\subsection{Memoryless property}

% It is well known that the exponential distribution has the memoryless property. Does it hold for simulations too? 

% First generate our standard case.

% \begin{pyblock}
% N = 10
% runlength = 1000
% labda = N/m
% d = m
% G = stats.uniform(loc = m-d, scale = 2.*d) 

% a = superposition(G, N, runlength)
% \end{pyblock} 

% Now select the interarrival times that exceed some number $x$ and
% subtract $x$. These new values should, hopefully, have the same
% distribution as the initial set of interarrival times.

% \begin{pyblock}
% x = 0.5 # threshold
% c = a[a>x] -x # select the interarrival times longer than x
% \end{pyblock} 

% Let's plot it
% \begin{pyblock}
% e = empericalDistribution(c)
% plt.plot(e.x, e.cdf , label = "emp")
% plt.plot(e.x,1.-np.exp(-labda*e.x), label = "th")
% plt.legend()
% plt.show()
% \end{pyblock} 

% This is quite ok. What is the threshold $x$ becomes larger, e.g., 1?

% \begin{pyblock}
% x = 2. # threshold
% c = a[a>x] -x # select the interarrival times longer than x

% e = empericalDistribution(c)
% plt.plot(e.x, e.cdf , label = "emp")
% plt.plot(e.x,1.-np.exp(-labda*e.x), label = "th")
% plt.legend()
% plt.show()
% \end{pyblock} 

% Now the result is not as nice. What if we increase the simulation length? 
% \begin{pyblock}
% N = 10
% runlength = 100000
% labda = N/m
% d = m
% G = stats.uniform(loc = m-d, scale = 2.*d) 

% a = superposition(G, N, runlength)

% x = 2. # threshold
% c = a[a>x] -x # select the interarrival times longer than x

% e = empericalDistribution(c)
% plt.plot(e.x, e.cdf , label = "emp")
% plt.plot(e.x,1.-np.exp(-labda*e.x), label = "th")
% plt.legend()
% plt.show()
% \end{pyblock} 

% It is interesting to see that now the memoryless property seems to
% hold again. But why do we need so many values to see this? 



% \subsection{Analysis of the number arrivals in an interval}

% Now I build the same data, but count the number of arrivals that occur in a certain interval. 

% First I compute, as above, a number of arrival times as seen by the counter.

% \begin{pyblock}
% m = 5.
% d = 2.
% G = stats.uniform(loc = m-d, scale = 2.*d) 

% N = 300
% runlength = 1000
% a = G.rvs((N, runlength))
% A = np.cumsum(a, axis = 1)
% A = np.sort(A.flatten())
% \end{pyblock} 

% Next, I make a histogram, that, is I chop up the entire simulation
% interval, from the first arrival time to the last, into a number of
% bins of equal length. Then I use $np.histogram$ to count the number of
% arrivals in each such interval.  There are $N*runlength$ arrivals in
% total.  I like the bins of such size that on average each bin will
% contain 50 arrivals. Thus, the number of bins, i.e., the number of intervals in which the entire simulation interval needs to chopped, should be $N*runlength/50$. 

% \begin{pyblock}
% #bins = N*runlength/50
% #p, x = np.histogram(A, bins = bins)
% \end{pyblock} 

% Here, $x$ contains the interval boundaries in which the simulation
% interval is chopped up. Therefore $I=x[1]-x[0]$ is the length of one
% such interval. The arrival rate in such interval must be $I*N/m$, as
% $N/m$ is the arrival rate per unit time. Therefore,
% \begin{pyblock}
% #I = x[1]- x[0]
% #labda = float(I)*N/m
% \end{pyblock} 

% Now I count the number of times a certain number of arrivals occured.
% \begin{pyblock}
% P =  np.bincount(p)
% \end{pyblock} 

% Finally, I want to fit a Poisson distribution to see how well the
% Poisson distribution fits the data.  I need the support of the
% measured data, and store in $x$. As $np.bincount$ only counts, it is
% necessary to normalize $P$.
% \begin{pyblock}
% x = range(p.min(), p.max())

% plt.plot(P/float(sum(P)))
% plt.plot(x, scipy.stats.poisson.pmf(x, labda)) 
% plt.show()
% \end{pyblock} 

% Not bad. However, some experimentation shows that when $N$ is small,
% like 30 or so, and the $runlength$ is short, in the order of 100 or
% so, the quality of the Poisson approximation is much less. I do not
% fully understand why that is the case.

% \begin{pyblock}
% N = 30
% runlength = 300
% a = G.rvs((N, runlength))
% A = np.cumsum(a, axis = 1)
% A = np.sort(A.flatten())

% bins = N*runlength/50
% p, x = np.histogram(A, bins = bins)

% I = x[1]- x[0]
% labda = float(I)*N/m

% P =  np.bincount(p)
% plt.plot(P/float(sum(P)))

% x = range(p.min(), p.max())
% plt.plot(x, scipy.stats.poisson.pmf(x, labda)) 
% plt.show()
% \end{pyblock} 



Overshoot verdeling? 

\section{A single server queue}
\label{sec:single-server-queue}

\section{A queueing network}
\label{sec:queueing-network}


\section{A queueing network with workload control}
\label{sec:queu-netw-with}



\section{Heat bath}
\label{sec:heat-bath}

\section{Nurse routing}
\label{sec:nurse-routing}

shift sheduling. setups. 


\section{An Assembly line}
\label{sec:an-assembly-line}




\Closesolutionfile{hint}
\Closesolutionfile{ans}

\clearpage
\section*{Hints}
\input{hint}

\clearpage
\section*{Solutions}
\input{ans}


\end{document}

simulatie van single server queue

simulatie van lopende band, idee met Marien.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
